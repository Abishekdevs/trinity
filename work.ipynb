{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1MphMJXR2QnS7iRS62ADcKmWgQ_BzTyHx",
      "authorship_tag": "ABX9TyM7uc18JkgP5vErvfSgAt7G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abishekdevs/trinity/blob/main/work.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade -q google-generativeai algoliasearch gspread google-auth"
      ],
      "metadata": {
        "id": "6-z5OnJiVCqL",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üìç AI Restaurant Explorer (V3 - Stable) { run: \"auto\" }\n",
        "LOCATION_INPUT = \"Mahabalipuram, TN, India\" #@param {type:\"string\"}\n",
        "\n",
        "import requests, json\n",
        "from google.colab import userdata\n",
        "\n",
        "def debug_geocode():\n",
        "    key = userdata.get('MAPS_API_KEY')\n",
        "    # Using a slightly different URL format for better compatibility\n",
        "    url = \"https://maps.googleapis.com/maps/api/geocode/json\"\n",
        "    params = {\n",
        "        \"address\": LOCATION_INPUT,\n",
        "        \"key\": key\n",
        "    }\n",
        "\n",
        "    print(f\"--- Debugging Connection ---\")\n",
        "    try:\n",
        "        response = requests.get(url, params=params)\n",
        "        data = response.json()\n",
        "\n",
        "        status = data.get(\"status\")\n",
        "        error_msg = data.get(\"error_message\", \"No error message provided.\")\n",
        "\n",
        "        if status == \"OK\":\n",
        "            results = data[\"results\"][0][\"geometry\"][\"location\"]\n",
        "            print(f\"‚úÖ Success! Found: {results}\")\n",
        "            return results\n",
        "        else:\n",
        "            print(f\"‚ùå Status: {status}\")\n",
        "            print(f\"‚ùå Details: {error_msg}\")\n",
        "\n",
        "            if status == \"REQUEST_DENIED\":\n",
        "                print(\"\\nüí° ACTION REQUIRED:\")\n",
        "                print(\"1. Ensure 'Geocoding API' is ENABLED in Cloud Console.\")\n",
        "                print(\"2. Ensure 'Billing' is linked to this specific project.\")\n",
        "                print(\"3. Ensure 'Application Restrictions' is set to 'None' in API Key settings.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Critical Error: {e}\")\n",
        "\n",
        "debug_geocode()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "MI_y_-Yyig2E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57518683-c92b-4b3b-8318-c4372491016b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Debugging Connection ---\n",
            "‚úÖ Success! Found: {'lat': 12.6207821, 'lng': 80.1944915}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'lat': 12.6207821, 'lng': 80.1944915}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sync up, reset _ erase algolia and sheet - updated with recent headers"
      ],
      "metadata": {
        "id": "n8bUxukRkoOU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üìçLogic to actually wipe the data after confirmation)\n",
        "Execute_cell_to_get_options = \"RUN\" #@param {type:\"string\"}\n",
        "\n",
        "# 1. ADDITIONAL IMPORTS\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# 2. UPDATED RESET LOGIC (Confirmation Button Pattern)\n",
        "def perform_actual_reset():\n",
        "    \"\"\"Logic to actually wipe the data after confirmation.\"\"\"\n",
        "    with output_log:\n",
        "        print(\"üóëÔ∏è Resetting GSheets and Algolia...\")\n",
        "        try:\n",
        "            # 1. Reset GSheets\n",
        "            sh = gc.open(WORKBOOK_NAME)\n",
        "            for sheet_name in [\"Restaurants\", \"Menus\"]:\n",
        "                ws = sh.worksheet(sheet_name)\n",
        "                ws.clear()\n",
        "                # Restore headers\n",
        "                if sheet_name == \"Restaurants\":\n",
        "                    ws.append_row(['timestamp', 'place_id', 'name', 'phone', 'location', 'city', 'state', 'country', 'cuisine', 'website', 'usp', 'market_gap', 'social_links'])\n",
        "                else:\n",
        "                    ws.append_row(['id', 'place_id', 'rest_name', 'item_name', 'price', 'category', 'is_unique_locally', 'competitive_reasoning'])\n",
        "\n",
        "            # 2. Clear Algolia Index\n",
        "            algolia_client.clear_objects(index_name=ALG_INDEX_NAME)\n",
        "            print(\"‚ú® Everything Reset! Sheets cleared and Algolia index emptied.\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Reset Error: {e}\")\n",
        "\n",
        "def on_reset_clicked(b):\n",
        "    \"\"\"Triggers the confirmation UI.\"\"\"\n",
        "    with output_log:\n",
        "        clear_output()\n",
        "        print(\"‚ö†Ô∏è ARE YOU SURE? This will wipe all data in GSheets and Algolia.\")\n",
        "\n",
        "        # Create confirmation buttons\n",
        "        confirm_btn = widgets.Button(description=\"YES, DELETE ALL\", button_style='danger')\n",
        "        cancel_btn = widgets.Button(description=\"NO, CANCEL\", button_style='warning')\n",
        "\n",
        "        def handle_confirm(b):\n",
        "            clear_output()\n",
        "            perform_actual_reset()\n",
        "\n",
        "        def handle_cancel(b):\n",
        "            clear_output()\n",
        "            print(\"‚ùå Reset cancelled.\")\n",
        "\n",
        "        confirm_btn.on_click(handle_confirm)\n",
        "        cancel_btn.on_click(handle_cancel)\n",
        "        display(widgets.HBox([confirm_btn, cancel_btn]))\n",
        "\n",
        "# 3. EXISTING SYNC LOGIC\n",
        "def on_sync_clicked(b):\n",
        "    with output_log:\n",
        "        clear_output()\n",
        "        print(\"üîÑ Starting Full Sync: GSheets -> Algolia...\")\n",
        "        try:\n",
        "            sh = gc.open(WORKBOOK_NAME)\n",
        "            records = sh.worksheet(\"Restaurants\").get_all_records()\n",
        "            if not records:\n",
        "                print(\"‚ö†Ô∏è No data in 'Restaurants' sheet to sync.\")\n",
        "                return\n",
        "            algolia_client.replace_all_objects(index_name=ALG_INDEX_NAME, objects=records)\n",
        "            res = algolia_client.list_indices()\n",
        "            count = next((idx.entries for idx in res.items if idx.name == ALG_INDEX_NAME), 0)\n",
        "            print(f\"‚úÖ Sync Complete! Total records in Algolia: {count}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Sync Error: {e}\")\n",
        "\n",
        "# 4. INITIALIZE UI\n",
        "btn_sync = widgets.Button(description=\"üîÑ Sync Now\", button_style='info')\n",
        "btn_reset = widgets.Button(description=\"üóëÔ∏è Full Reset\", button_style='danger')\n",
        "output_log = widgets.Output()\n",
        "\n",
        "btn_sync.on_click(on_sync_clicked)\n",
        "btn_reset.on_click(on_reset_clicked)\n",
        "\n",
        "print(\"\\n--- üõ†Ô∏è CONTROL PANEL ---\")\n",
        "display(widgets.HBox([btn_sync, btn_reset]), output_log)"
      ],
      "metadata": {
        "id": "QZONRB2mYcCW",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üìç AI Market Intelligence Explorer (v22 - Full Data + Is Unique Locally)\n",
        "LOCATION_INPUT = \"Tambaram, Chennai TN, India\" #@param {type:\"string\"}\n",
        "RADIUS_METERS = 7000 #@param {type:\"slider\", min:500, max:50000, step:500}\n",
        "WORKBOOK_NAME = \"V1 Advanced Market Intelligence 2025\" #@param {type:\"string\"}\n",
        "\n",
        "import requests, json, time, uuid, re\n",
        "from google import genai\n",
        "from google.colab import userdata, auth\n",
        "from google.auth import default\n",
        "import gspread\n",
        "from algoliasearch.search.client import SearchClientSync\n",
        "\n",
        "# --- INITIALIZATION ---\n",
        "try:\n",
        "    auth.authenticate_user()\n",
        "    creds, _ = default()\n",
        "    gc = gspread.authorize(creds)\n",
        "\n",
        "    client = genai.Client(api_key=userdata.get('GEMINI_API_KEY'))\n",
        "    MAPS_API_KEY = userdata.get('MAPS_API_KEY')\n",
        "    algolia_client = SearchClientSync(userdata.get('ALGOLIA_APP_ID'), userdata.get('ALGOLIA_API_KEY'))\n",
        "    ALG_INDEX_NAME = userdata.get('ALGOLIA_INDEX_NAME')\n",
        "\n",
        "    print(\"‚úÖ All services Initialized.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Setup Error: {e}\")\n",
        "\n",
        "# --- HELPER FUNCTIONS ---\n",
        "\n",
        "def get_sheets(workbook_name):\n",
        "    try:\n",
        "        sh = gc.open(workbook_name)\n",
        "    except gspread.SpreadsheetNotFound:\n",
        "        sh = gc.create(workbook_name)\n",
        "\n",
        "    def get_or_create(name, header):\n",
        "        try:\n",
        "            ws = sh.worksheet(name)\n",
        "        except gspread.WorksheetNotFound:\n",
        "            ws = sh.add_worksheet(name, 1000, len(header))\n",
        "        if not ws.get_all_values():\n",
        "            ws.append_row(header)\n",
        "        return ws\n",
        "\n",
        "    # Headers for Restaurants\n",
        "    ws_rest = get_or_create(\"Restaurants\", [\n",
        "        'timestamp', 'place_id', 'name', 'phone', 'location',\n",
        "        'city', 'state', 'country', 'cuisine', 'website',\n",
        "        'usp', 'market_gap', 'social_links'\n",
        "    ])\n",
        "    # Headers for Menus (Including is_unique_locally)\n",
        "    ws_menu = get_or_create(\"Menus\", [\n",
        "        'id', 'place_id', 'rest_name', 'item_name', 'price',\n",
        "        'category', 'is_unique_locally', 'competitive_reasoning'\n",
        "    ])\n",
        "    return ws_rest, ws_menu\n",
        "\n",
        "def parse_address_components(components):\n",
        "    city = state = country = \"N/A\"\n",
        "    for c in components:\n",
        "        types = c.get('types', [])\n",
        "        if 'locality' in types: city = c.get('longText', 'N/A')\n",
        "        elif 'administrative_area_level_1' in types: state = c.get('shortText', 'N/A')\n",
        "        elif 'country' in types: country = c.get('longText', 'N/A')\n",
        "    return city, state, country\n",
        "\n",
        "def enrich_market_intelligence(restaurant_name, location):\n",
        "    prompt = (\n",
        "        f\"Research the restaurant: '{restaurant_name}' at '{location}'.\\n\"\n",
        "        \"Return ONLY JSON. Rules:\\n\"\n",
        "        \"- cuisine: Max 3 words.\\n\"\n",
        "        \"- usp: Max 3 words, catchy caption.\\n\"\n",
        "        \"- market_gap: Exactly one simple sentence.\\n\"\n",
        "        \"- menu: get all menu items from the restaurant, out of that, mark 3 unique items with 'competitive_reasoning' relative to local rivals.\\n\\n\"\n",
        "        \"JSON: {'details': {'cuisine', 'website', 'usp', 'market_gap', 'social_links': []}, \"\n",
        "        \"'menu': [{'item_name', 'price', 'category', 'is_unique_locally', 'competitive_reasoning'}]}\"\n",
        "    )\n",
        "    try:\n",
        "        response = client.models.generate_content(model='gemini-2.0-flash', contents=prompt)\n",
        "        match = re.search(r'\\{.*\\}', response.text, re.DOTALL)\n",
        "        if match:\n",
        "            data = json.loads(match.group())\n",
        "            d = data.get('details', {})\n",
        "            # Text clipping safety\n",
        "            if d.get('usp'): d['usp'] = \" \".join(d['usp'].split()[:3])\n",
        "            if d.get('cuisine'): d['cuisine'] = \" \".join(d['cuisine'].split()[:3])\n",
        "            return data\n",
        "    except: return None\n",
        "\n",
        "# --- MAIN APP ---\n",
        "\n",
        "def run_app():\n",
        "    print(f\"üöÄ Scouting {LOCATION_INPUT}...\")\n",
        "    ws_rest, ws_menu = get_sheets(WORKBOOK_NAME)\n",
        "\n",
        "    # DEDUP: Pull existing Place IDs to avoid redundant API calls\n",
        "    existing_data = ws_rest.get_all_values()\n",
        "    existing_ids = {row[1] for row in existing_data[1:]}\n",
        "\n",
        "    # 1. Geocoding\n",
        "    geo = requests.get(\"https://maps.googleapis.com/maps/api/geocode/json\",\n",
        "                       params={\"address\": LOCATION_INPUT, \"key\": MAPS_API_KEY}).json()\n",
        "    if geo['status'] != 'OK': return print(\"‚ùå Geocoding Failed.\")\n",
        "    lat, lng = geo['results'][0]['geometry']['location'].values()\n",
        "\n",
        "    # 2. Nearby Search\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"X-Goog-Api-Key\": MAPS_API_KEY,\n",
        "        \"X-Goog-FieldMask\": \"places.id,places.displayName,places.formattedAddress,places.internationalPhoneNumber,places.addressComponents\"\n",
        "    }\n",
        "    search_data = {\n",
        "        \"includedTypes\": [\"restaurant\"],\n",
        "        \"maxResultCount\": 15,\n",
        "        \"locationRestriction\": {\"circle\": {\"center\": {\"latitude\": lat, \"longitude\": lng}, \"radius\": RADIUS_METERS}}\n",
        "    }\n",
        "    places_resp = requests.post(\"https://places.googleapis.com/v1/places:searchNearby\",\n",
        "                                headers=headers, json=search_data).json()\n",
        "    places = places_resp.get('places', [])\n",
        "\n",
        "    if not places: return print(\"üìç No restaurants found.\")\n",
        "\n",
        "    all_menu_rows = []\n",
        "    curr_time = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "    for p in places:\n",
        "        pid = p.get('id')\n",
        "        name = p['displayName']['text']\n",
        "\n",
        "        if pid in existing_ids:\n",
        "            print(f\"‚è≠Ô∏è Skipping {name} (Already Audited)\")\n",
        "            continue\n",
        "\n",
        "        loc = p['formattedAddress']\n",
        "        phone = p.get('internationalPhoneNumber', 'N/A')\n",
        "        city, state, country = parse_address_components(p.get('addressComponents', []))\n",
        "\n",
        "        print(f\"üîé Analyzing: {name}...\")\n",
        "        ai = enrich_market_intelligence(name, loc)\n",
        "        if not ai: continue\n",
        "\n",
        "        d, menu_items = ai.get('details', {}), ai.get('menu', [])\n",
        "\n",
        "        # Save Restaurant Row\n",
        "        ws_rest.append_row([\n",
        "            curr_time, pid, name, phone, loc, city, state, country,\n",
        "            d.get('cuisine'), d.get('website'), d.get('usp'),\n",
        "            d.get('market_gap'), \", \".join(d.get('social_links', []))\n",
        "        ])\n",
        "\n",
        "        # Batch Menu Items (Including is_unique_locally)\n",
        "        for m in menu_items:\n",
        "            all_menu_rows.append([\n",
        "                str(uuid.uuid4()),\n",
        "                pid,\n",
        "                name,\n",
        "                m.get('item_name'),\n",
        "                m.get('price'),\n",
        "                m.get('category'),\n",
        "                m.get('is_unique_locally'), # ADDED BACK\n",
        "                m.get('competitive_reasoning')\n",
        "            ])\n",
        "\n",
        "        # Sync to Algolia\n",
        "        try:\n",
        "            algolia_client.save_object(index_name=ALG_INDEX_NAME, body={\n",
        "                \"objectID\": pid,\n",
        "                \"name\": name,\n",
        "                \"phone\": phone,\n",
        "                \"location\": loc,\n",
        "                \"city\": city,\n",
        "                \"country\": country,\n",
        "                \"cuisine\": d.get('cuisine'),\n",
        "                \"usp\": d.get('usp'),\n",
        "                \"market_gap\": d.get('market_gap'),\n",
        "                \"menu\": menu_items\n",
        "            })\n",
        "        except: pass\n",
        "\n",
        "        time.sleep(1)\n",
        "\n",
        "    # Final Batch Upload for Menus\n",
        "    if all_menu_rows:\n",
        "        ws_menu.append_rows(all_menu_rows)\n",
        "        print(f\"üìä Added {len(all_menu_rows)} menu items to Sheet.\")\n",
        "\n",
        "    print(f\"\\n‚ú® Market Intelligence Audit Complete!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_app()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ync4Ca12foix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ADVANCED BATCH PROCESSOR ---\n",
        "#@title üì• Secure Rest Batch Processor (Input from Sheet)\n",
        "WORKBOOK_NAME = \"V1 Advanced Market Intelligence 2025\" #@param {type:\"string\"}\n",
        "INPUT_TAB_NAME = \"Rest_Queue\" #@param {type:\"string\"}\n",
        "\n",
        "def run_secure_batch_processor():\n",
        "    print(f\"üìÇ Accessing {WORKBOOK_NAME}...\")\n",
        "    sh = gc.open(WORKBOOK_NAME)\n",
        "\n",
        "    try:\n",
        "        ws_input = sh.worksheet(INPUT_TAB_NAME)\n",
        "    except gspread.WorksheetNotFound:\n",
        "        return print(f\"‚ùå Tab '{INPUT_TAB_NAME}' not found.\")\n",
        "\n",
        "    ws_rest, ws_menu = get_sheets(WORKBOOK_NAME)\n",
        "\n",
        "    # Get all rows. Row 1 is header. Row 2 is our first target.\n",
        "    rows = ws_input.get_all_values()\n",
        "    if len(rows) <= 1:\n",
        "        return print(\"üì≠ Input Queue is empty.\")\n",
        "\n",
        "    # We process one by one and delete/update to keep the queue clean\n",
        "    # We loop through a copy of the list so we don't mess up the indexing\n",
        "    queries_to_process = rows[1:]\n",
        "\n",
        "    all_menu_rows = []\n",
        "    curr_time = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "    print(f\"üöÄ Processing {len(queries_to_process)} entries...\")\n",
        "\n",
        "    for row_data in queries_to_process:\n",
        "        query = row_data[0] # The Name + Address\n",
        "        if not query:\n",
        "            ws_input.delete_rows(2) # Remove empty rows\n",
        "            continue\n",
        "\n",
        "        print(f\"üîé Current Task: {query}\")\n",
        "\n",
        "        try:\n",
        "            # 1. Search Google Maps\n",
        "            headers = {\n",
        "                \"Content-Type\": \"application/json\",\n",
        "                \"X-Goog-Api-Key\": MAPS_API_KEY,\n",
        "                \"X-Goog-FieldMask\": \"places.id,places.displayName,places.formattedAddress,places.internationalPhoneNumber,places.addressComponents\"\n",
        "            }\n",
        "            resp = requests.post(\"https://places.googleapis.com/v1/places:searchText\",\n",
        "                                 headers=headers, json={\"textQuery\": query}).json()\n",
        "\n",
        "            places = resp.get('places', [])\n",
        "            if not places:\n",
        "                print(f\"‚ö†Ô∏è Not found. Skipping.\")\n",
        "                ws_input.update_cell(2, 2, \"FAILED: Not Found\")\n",
        "                # Move failed items to the bottom or keep them? Let's move to a \"Failed\" sheet or just skip.\n",
        "                # For now, we'll just leave it and you can manually check.\n",
        "                continue\n",
        "\n",
        "            p = places[0]\n",
        "            pid, name, loc = p.get('id'), p['displayName']['text'], p['formattedAddress']\n",
        "\n",
        "            # 2. AI Enrichment\n",
        "            ai = enrich_market_intelligence(name, loc)\n",
        "            if not ai:\n",
        "                ws_input.update_cell(2, 2, \"FAILED: AI Error\")\n",
        "                continue\n",
        "\n",
        "            d, menu_items = ai.get('details', {}), ai.get('menu', [])\n",
        "            city, state, country = parse_address_components(p.get('addressComponents', []))\n",
        "\n",
        "            # 3. Save to Main Sheets\n",
        "            ws_rest.append_row([\n",
        "                curr_time, pid, name, p.get('internationalPhoneNumber', 'N/A'),\n",
        "                loc, city, state, country, d.get('cuisine'), d.get('website'),\n",
        "                d.get('usp'), d.get('market_gap'), \", \".join(d.get('social_links', []))\n",
        "            ])\n",
        "\n",
        "            for m in menu_items:\n",
        "                all_menu_rows.append([\n",
        "                    str(uuid.uuid4()), pid, name, m.get('item_name'),\n",
        "                    m.get('price'), m.get('category'), m.get('is_unique_locally'),\n",
        "                    m.get('competitive_reasoning')\n",
        "                ])\n",
        "\n",
        "            # 4. Sync to Algolia\n",
        "            algolia_client.save_object(index_name=ALG_INDEX_NAME, body={\n",
        "                \"objectID\": pid,\n",
        "                \"name\": name,\n",
        "                \"phone\": p.get('internationalPhoneNumber', 'N/A'),\n",
        "                \"location\": loc,\n",
        "                \"city\": city,\n",
        "                \"country\": country,\n",
        "                \"cuisine\": d.get('cuisine'),\n",
        "                \"usp\": d.get('usp'),\n",
        "                \"market_gap\": d.get('market_gap'),\n",
        "                \"menu\": menu_items\n",
        "            })\n",
        "\n",
        "            # 5. Cleanup: Delete the row from Input_Queue as it's finished\n",
        "            ws_input.delete_rows(2)\n",
        "            print(f\"‚úÖ Success! Row removed from Queue.\")\n",
        "\n",
        "            # Batch save menus every 5 restaurants to prevent data loss\n",
        "            if len(all_menu_rows) > 10:\n",
        "                ws_menu.append_rows(all_menu_rows)\n",
        "                all_menu_rows = []\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error processing {query}: {e}\")\n",
        "            ws_input.update_cell(2, 2, f\"ERROR: {str(e)[:50]}\")\n",
        "            break # Stop if there's a major connection error\n",
        "\n",
        "    # Final Menu Save\n",
        "    if all_menu_rows:\n",
        "        ws_menu.append_rows(all_menu_rows)\n",
        "\n",
        "    print(\"\\n‚ú® Batch Audit Session Finished.\")\n",
        "\n",
        "run_secure_batch_processor()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "dpjCp3uBenew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- MULTI-LOCATION BATCH SCOUT ---\n",
        "#@title üì° Multi-Location Scout (Input from Sheet)\n",
        "WORKBOOK_NAME = \"V1 Advanced Market Intelligence 2025\" #@param {type:\"string\"}\n",
        "INPUT_TAB_NAME = \"Loc_queue\" #@param {type:\"string\"}\n",
        "RADIUS_METERS = 7000 #@param {type:\"slider\", min:500, max:50000, step:500}\n",
        "\n",
        "def run_multi_location_scout():\n",
        "    print(f\"üìÇ Accessing {WORKBOOK_NAME}...\")\n",
        "    sh = gc.open(WORKBOOK_NAME)\n",
        "\n",
        "    try:\n",
        "        ws_input = sh.worksheet(INPUT_TAB_NAME)\n",
        "    except gspread.WorksheetNotFound:\n",
        "        return print(f\"‚ùå Tab '{INPUT_TAB_NAME}' not found.\")\n",
        "\n",
        "    ws_rest, ws_menu = get_sheets(WORKBOOK_NAME)\n",
        "\n",
        "    # Get the list of locations to scout\n",
        "    rows = ws_input.get_all_values()\n",
        "    if len(rows) <= 1:\n",
        "        return print(\"üì≠ No locations found in the queue.\")\n",
        "\n",
        "    locations_to_scout = rows[1:] # Skip header\n",
        "    existing_ids = {row[1] for row in ws_rest.get_all_values()[1:]}\n",
        "    curr_time = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "    for loc_row in locations_to_scout:\n",
        "        location_name = loc_row[0]\n",
        "        if not location_name:\n",
        "            ws_input.delete_rows(2)\n",
        "            continue\n",
        "\n",
        "        print(f\"\\nüåç SCOUTING AREA: {location_name}...\")\n",
        "\n",
        "        # 1. Geocoding the area\n",
        "        geo = requests.get(\"https://maps.googleapis.com/maps/api/geocode/json\",\n",
        "                           params={\"address\": location_name, \"key\": MAPS_API_KEY}).json()\n",
        "\n",
        "        if geo['status'] != 'OK':\n",
        "            print(f\"‚ùå Could not find location: {location_name}\")\n",
        "            ws_input.update_cell(2, 2, \"FAILED: Invalid Location\")\n",
        "            continue\n",
        "\n",
        "        lat, lng = geo['results'][0]['geometry']['location'].values()\n",
        "\n",
        "        # 2. Search Nearby Restaurants\n",
        "        headers = {\n",
        "            \"Content-Type\": \"application/json\",\n",
        "            \"X-Goog-Api-Key\": MAPS_API_KEY,\n",
        "            \"X-Goog-FieldMask\": \"places.id,places.displayName,places.formattedAddress,places.internationalPhoneNumber,places.addressComponents\"\n",
        "        }\n",
        "        search_data = {\n",
        "            \"includedTypes\": [\"restaurant\"],\n",
        "            \"maxResultCount\": 15,\n",
        "            \"locationRestriction\": {\"circle\": {\"center\": {\"latitude\": lat, \"longitude\": lng}, \"radius\": RADIUS_METERS}}\n",
        "        }\n",
        "        places_resp = requests.post(\"https://places.googleapis.com/v1/places:searchNearby\",\n",
        "                                    headers=headers, json=search_data).json()\n",
        "\n",
        "        places = places_resp.get('places', [])\n",
        "        print(f\"üìç Found {len(places)} restaurants in {location_name}.\")\n",
        "\n",
        "        all_menu_rows = []\n",
        "\n",
        "        # 3. Process each restaurant found in this area\n",
        "        for p in places:\n",
        "            pid, name, addr = p.get('id'), p['displayName']['text'], p['formattedAddress']\n",
        "\n",
        "            if pid in existing_ids:\n",
        "                continue\n",
        "\n",
        "            print(f\"üîé Analyzing: {name}...\")\n",
        "            ai = enrich_market_intelligence(name, addr)\n",
        "            if not ai: continue\n",
        "\n",
        "            d, menu_items = ai.get('details', {}), ai.get('menu', [])\n",
        "            city, state, country = parse_address_components(p.get('addressComponents', []))\n",
        "\n",
        "            # Save Restaurant\n",
        "            ws_rest.append_row([\n",
        "                curr_time, pid, name, p.get('internationalPhoneNumber', 'N/A'),\n",
        "                addr, city, state, country, d.get('cuisine'), d.get('website'),\n",
        "                d.get('usp'), d.get('market_gap'), \", \".join(d.get('social_links', []))\n",
        "            ])\n",
        "\n",
        "            # Prepare Menus\n",
        "            for m in menu_items:\n",
        "                all_menu_rows.append([\n",
        "                    str(uuid.uuid4()), pid, name, m.get('item_name'),\n",
        "                    m.get('price'), m.get('category'), m.get('is_unique_locally'),\n",
        "                    m.get('competitive_reasoning')\n",
        "                ])\n",
        "\n",
        "            # Algolia Sync\n",
        "            try:\n",
        "                algolia_client.save_object(index_name=ALG_INDEX_NAME, body={\n",
        "                \"objectID\": pid,\n",
        "                \"name\": name,\n",
        "                \"phone\": p.get('internationalPhoneNumber', 'N/A'),\n",
        "                \"location\": addr,\n",
        "                \"city\": city,\n",
        "                \"country\": country,\n",
        "                \"cuisine\": d.get('cuisine'),\n",
        "                \"usp\": d.get('usp'),\n",
        "                \"market_gap\": d.get('market_gap'),\n",
        "                \"menu\": menu_items\n",
        "                })\n",
        "            except: pass\n",
        "\n",
        "            existing_ids.add(pid) # Track locally to prevent duplicates in same run\n",
        "            time.sleep(0.5)\n",
        "\n",
        "        # Batch save menus for this specific location\n",
        "        if all_menu_rows:\n",
        "            ws_menu.append_rows(all_menu_rows)\n",
        "\n",
        "        # 4. Cleanup: Remove this location from the queue\n",
        "        ws_input.delete_rows(2)\n",
        "        print(f\"‚úÖ Finished {location_name}. Row removed.\")\n",
        "\n",
        "    print(\"\\n‚ú® All locations scouted successfully!\")\n",
        "\n",
        "run_multi_location_scout()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "3U5jkk5nhU_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import time\n",
        "import uuid\n",
        "import re\n",
        "import gspread\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "#@title üì° Food walk scout with cuisine type, diet pref\n",
        "WALK_LOCATION = \"Connaught Place, New Delhi\" #@param {type:\"string\"}\n",
        "WALK_NAME = \"The Heart of Lutyens\" #@param {type:\"string\"}\n",
        "CUISINE_TYPE = \"North Indian\" #@param {type:\"string\"}\n",
        "DIETARY_PREFERENCE = \"Vegetarian\" #@param [\"Vegetarian\", \"Non-Vegetarian\", \"Any\"]\n",
        "ALG_WALK_INDEX = \"prod_MENU_Walk\"\n",
        "\n",
        "def get_walking_duration(origin_id, dest_id):\n",
        "    \"\"\"Calculates walking time between two Google Place IDs.\"\"\"\n",
        "    url = \"https://maps.googleapis.com/maps/api/distancematrix/json\"\n",
        "    params = {\n",
        "        \"origins\": f\"place_id:{origin_id}\",\n",
        "        \"destinations\": f\"place_id:{dest_id}\",\n",
        "        \"mode\": \"walking\",\n",
        "        \"key\": MAPS_API_KEY\n",
        "    }\n",
        "    try:\n",
        "        data = requests.get(url, params=params).json()\n",
        "        if data['rows'][0]['elements'][0]['status'] == 'OK':\n",
        "            return data['rows'][0]['elements'][0]['duration']['text']\n",
        "    except: return \"5-10 mins walk\"\n",
        "    return \"short walk\"\n",
        "\n",
        "def run_pro_food_walk():\n",
        "    print(f\"üëü Curating Walk: {WALK_NAME}...\")\n",
        "    sh = gc.open(WORKBOOK_NAME)\n",
        "\n",
        "    # 1. Ensure Worksheet exists with all headers\n",
        "    try:\n",
        "        ws_walk = sh.worksheet(\"Food_Walks\")\n",
        "    except gspread.WorksheetNotFound:\n",
        "        header = ['walk_id', 'walk_name', 'stop_no', 'rest_name', 'cuisine_type', 'is_veg_friendly',\n",
        "                  'place_id', 'dish_to_try', 'price_est', 'google_price_level', 'walking_time_to_next',\n",
        "                  'rest_address', 'locality', 'city', 'state', 'country',\n",
        "                  'itinerary', 'is_open_now', 'map_link', 'timestamp']\n",
        "        ws_walk = sh.add_worksheet(\"Food_Walks\", 1000, len(header))\n",
        "        ws_walk.append_row(header)\n",
        "\n",
        "    # 2. Get Geolocation for Center Point\n",
        "    geo = requests.get(\"https://maps.googleapis.com/maps/api/geocode/json\",\n",
        "                       params={\"address\": WALK_LOCATION, \"key\": MAPS_API_KEY}).json()\n",
        "    lat, lng = geo['results'][0]['geometry']['location'].values()\n",
        "\n",
        "    # 3. Get Data via SearchText (New API)\n",
        "    text_query = f\"{DIETARY_PREFERENCE} {CUISINE_TYPE} restaurants in {WALK_LOCATION}\"\n",
        "\n",
        "    headers = {\n",
        "        \"X-Goog-Api-Key\": MAPS_API_KEY,\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        # We must use 'places.id' and 'places.name' (which is the resource name)\n",
        "        \"X-Goog-FieldMask\": \"places.id,places.displayName,places.formattedAddress,places.addressComponents,places.priceLevel,places.types,places.servesVegetarianFood,places.rating\"\n",
        "    }\n",
        "\n",
        "    search_data = {\n",
        "        \"textQuery\": text_query,\n",
        "        \"locationBias\": {\n",
        "            \"circle\": {\n",
        "                \"center\": {\"latitude\": lat, \"longitude\": lng},\n",
        "                \"radius\": 2000\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    response = requests.post(\"https://places.googleapis.com/v1/places:searchText\",\n",
        "                             headers=headers, json=search_data)\n",
        "    places = response.json().get('places', [])\n",
        "\n",
        "    if not places:\n",
        "        print(\"‚ùå No places found. Check your API Key or Query.\")\n",
        "        return\n",
        "\n",
        "    # 4. AI Design Context\n",
        "    restaurants_context = \"\\n\".join([\n",
        "        f\"- {p['displayName']['text']} (ID: {p['id']}) [Rating: {p.get('rating', 'N/A')}]\"\n",
        "        for p in places\n",
        "    ])\n",
        "\n",
        "    prompt = (\n",
        "        f\"Design a 3-stop {DIETARY_PREFERENCE} {CUISINE_TYPE} food walk called '{WALK_NAME}' in {WALK_LOCATION}.\\n\"\n",
        "        f\"Available Spots:\\n{restaurants_context}\\n\\n\"\n",
        "        \"Return ONLY JSON: {'stops': [{'stop_no', 'place_id', 'rest_name', 'dish_to_try', 'price_est', 'itinerary'}]}\"\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        ai_response = client.models.generate_content(model='gemini-2.0-flash', contents=prompt)\n",
        "        walk_data = json.loads(re.search(r'\\{.*\\}', ai_response.text, re.DOTALL).group())\n",
        "        stops = walk_data['stops']\n",
        "\n",
        "        walk_id = str(uuid.uuid4())[:8]\n",
        "        curr_time = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "        map_query = \"/\".join([s['rest_name'].replace(\" \",\"+\") for s in stops])\n",
        "        full_map_link = f\"https://www.google.com/maps/dir/{map_query}\"\n",
        "\n",
        "        final_rows = []\n",
        "        for i, stop in enumerate(stops):\n",
        "            # Walking duration\n",
        "            walking_time = \"Finish\"\n",
        "            if i < len(stops) - 1:\n",
        "                walking_time = get_walking_duration(stop['place_id'], stops[i+1]['place_id'])\n",
        "\n",
        "            # Match stop with Google data\n",
        "            p_data = next((p for p in places if p['id'] == stop['place_id']), {})\n",
        "\n",
        "            # --- EXTRACT DATA SAFELY ---\n",
        "            # IMPORTANT: In New API, place_id is simply 'id'\n",
        "            place_id_val = p_data.get('id', stop['place_id'])\n",
        "            full_address = p_data.get('formattedAddress', 'N/A')\n",
        "            components = p_data.get('addressComponents', [])\n",
        "\n",
        "            def find_comp(type_list):\n",
        "                for c in components:\n",
        "                    if any(t in c.get('types', []) for t in type_list):\n",
        "                        return c.get('longText', 'N/A')\n",
        "                return \"N/A\"\n",
        "\n",
        "            locality = find_comp([\"locality\", \"sublocality_level_1\"])\n",
        "            city = find_comp([\"administrative_area_level_2\", \"locality\"])\n",
        "            state = find_comp([\"administrative_area_level_1\"])\n",
        "            country = find_comp([\"country\"])\n",
        "\n",
        "            raw_types = p_data.get('types', [])\n",
        "            cuisine = next((t.replace(\"_restaurant\", \"\").replace(\"_\", \" \").title()\n",
        "                           for t in raw_types if \"restaurant\" in t and t != \"restaurant\"), CUISINE_TYPE)\n",
        "            is_veg = \"Yes\" if p_data.get('servesVegetarianFood') else \"No\"\n",
        "            price_lvl = p_data.get('priceLevel', 'N/A').replace(\"PRICE_LEVEL_\", \"\")\n",
        "\n",
        "            # 5. Prepare Row for GSheets\n",
        "            row = [\n",
        "                walk_id, WALK_NAME, stop['stop_no'], stop['rest_name'], cuisine, is_veg,\n",
        "                place_id_val, stop['dish_to_try'], stop['price_est'], price_lvl,\n",
        "                walking_time, full_address, locality, city, state, country,\n",
        "                stop['itinerary'], \"Yes\", full_map_link, curr_time\n",
        "            ]\n",
        "            final_rows.append(row)\n",
        "\n",
        "            # 6. Sync to Algolia\n",
        "            algolia_client.save_object(index_name=ALG_WALK_INDEX, body={\n",
        "                \"objectID\": f\"{walk_id}_{stop['stop_no']}\",\n",
        "                \"walk_name\": WALK_NAME,\n",
        "                \"walk_id\": walk_id,\n",
        "                \"cuisine_type\": cuisine,\n",
        "                \"is_veg_friendly\": is_veg,\n",
        "                \"place_id\": place_id_val,\n",
        "                \"rest_address\": full_address,\n",
        "                \"locality\": locality,\n",
        "                \"city\": city,\n",
        "                \"state\": state,\n",
        "                \"country\": country,\n",
        "                **stop\n",
        "            })\n",
        "\n",
        "        ws_walk.append_rows(final_rows)\n",
        "        print(f\"‚úÖ Success! {WALK_NAME} curated with all location fields.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error during processing: {e}\")\n",
        "\n",
        "run_pro_food_walk()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "W9zcGchlJLgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import time\n",
        "import uuid\n",
        "import re\n",
        "import gspread\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "# --- MULTI- food walk scout ---\n",
        "#@title üì° Multi-Food walk batch Scout (Input from Sheet)\n",
        "INPUT_TAB_NAME = \"Walk_Queue\"  #@param {type:\"string\"}\n",
        "OUTPUT_TAB_NAME = \"Food_Walks\"  #@param {type:\"string\"}\n",
        "ALG_WALK_INDEX = \"prod_MENU_Walk\"\n",
        "\n",
        "def get_walking_duration(origin_id, dest_id):\n",
        "    \"\"\"Calculates walking time between two Google Place IDs.\"\"\"\n",
        "    url = \"https://maps.googleapis.com/maps/api/distancematrix/json\"\n",
        "    params = {\n",
        "        \"origins\": f\"place_id:{origin_id}\",\n",
        "        \"destinations\": f\"place_id:{dest_id}\",\n",
        "        \"mode\": \"walking\",\n",
        "        \"key\": MAPS_API_KEY\n",
        "    }\n",
        "    try:\n",
        "        data = requests.get(url, params=params).json()\n",
        "        if data['rows'][0]['elements'][0]['status'] == 'OK':\n",
        "            return data['rows'][0]['elements'][0]['duration']['text']\n",
        "    except: return \"5-10 mins walk\"\n",
        "    return \"short walk\"\n",
        "\n",
        "def process_single_walk(sh, walk_input):\n",
        "    \"\"\"Core logic to curate one walk based on row input.\"\"\"\n",
        "    location = walk_input['WALK_LOCATION']\n",
        "    name = walk_input['WALK_NAME']\n",
        "    cuisine_req = walk_input['CUISINE_TYPE']\n",
        "    dietary_req = walk_input['DIETARY_PREFERENCE']\n",
        "\n",
        "    # 1. Get Geolocation\n",
        "    geo = requests.get(\"https://maps.googleapis.com/maps/api/geocode/json\",\n",
        "                       params={\"address\": location, \"key\": MAPS_API_KEY}).json()\n",
        "    if not geo.get('results'):\n",
        "        print(f\"‚ùå Could not find location: {location}\")\n",
        "        return False\n",
        "    lat, lng = geo['results'][0]['geometry']['location'].values()\n",
        "\n",
        "    # 2. Get Data via SearchText (New API)\n",
        "    text_query = f\"{dietary_req} {cuisine_req} restaurants in {location}\"\n",
        "    headers = {\n",
        "        \"X-Goog-Api-Key\": MAPS_API_KEY,\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"X-Goog-FieldMask\": \"places.id,places.displayName,places.formattedAddress,places.addressComponents,places.priceLevel,places.types,places.servesVegetarianFood,places.rating\"\n",
        "    }\n",
        "    search_data = {\n",
        "        \"textQuery\": text_query,\n",
        "        \"locationBias\": {\"circle\": {\"center\": {\"latitude\": lat, \"longitude\": lng}, \"radius\": 2000}}\n",
        "    }\n",
        "\n",
        "    places_resp = requests.post(\"https://places.googleapis.com/v1/places:searchText\",\n",
        "                                headers=headers, json=search_data).json()\n",
        "    places = places_resp.get('places', [])\n",
        "    if not places:\n",
        "        print(f\"‚ùå No restaurants found for: {name}\")\n",
        "        return False\n",
        "\n",
        "    # 3. AI Design\n",
        "    restaurants_context = \"\\n\".join([f\"- {p['displayName']['text']} (ID: {p['id']})\" for p in places[:10]])\n",
        "    prompt = (\n",
        "        f\"Design a 3-stop {dietary_req} {cuisine_req} food walk called '{name}' in {location}.\\n\"\n",
        "        f\"Available Spots:\\n{restaurants_context}\\n\\n\"\n",
        "        \"Return ONLY JSON: {'stops': [{'stop_no', 'place_id', 'rest_name', 'dish_to_try', 'price_est', 'itinerary'}]}\"\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = client.models.generate_content(model='gemini-2.0-flash', contents=prompt)\n",
        "        walk_data = json.loads(re.search(r'\\{.*\\}', response.text, re.DOTALL).group())\n",
        "        stops = walk_data['stops']\n",
        "\n",
        "        walk_id = str(uuid.uuid4())[:8]\n",
        "        curr_time = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "        map_query = \"/\".join([s['rest_name'].replace(\" \",\"+\") for s in stops])\n",
        "        full_map_link = f\"https://www.google.com/maps/dir/{map_query}\"\n",
        "\n",
        "        final_rows = []\n",
        "        for i, stop in enumerate(stops):\n",
        "            walking_time = \"Finish\" if i == len(stops)-1 else get_walking_duration(stop['place_id'], stops[i+1]['place_id'])\n",
        "            p_data = next((p for p in places if p['id'] == stop['place_id']), {})\n",
        "\n",
        "            # Location Extraction\n",
        "            comp = p_data.get('addressComponents', [])\n",
        "            def find_c(ts): return next((c['longText'] for c in comp if any(t in c['types'] for t in ts)), \"N/A\")\n",
        "\n",
        "            locality = find_c([\"locality\", \"sublocality_level_1\"])\n",
        "            city = find_c([\"administrative_area_level_2\", \"locality\"])\n",
        "            full_addr = p_data.get('formattedAddress', 'N/A')\n",
        "\n",
        "            row = [\n",
        "                walk_id, name, stop['stop_no'], stop['rest_name'], cuisine_req, dietary_req,\n",
        "                p_data.get('id'), stop['dish_to_try'], stop['price_est'],\n",
        "                p_data.get('priceLevel', 'N/A').replace(\"PRICE_LEVEL_\", \"\"),\n",
        "                walking_time, full_addr, locality, city,\n",
        "                find_c([\"administrative_area_level_1\"]), find_c([\"country\"]),\n",
        "                stop['itinerary'], \"Yes\", full_map_link, curr_time\n",
        "            ]\n",
        "            final_rows.append(row)\n",
        "\n",
        "            # Sync to Algolia\n",
        "            algolia_client.save_object(index_name=ALG_WALK_INDEX, body={\n",
        "                \"objectID\": f\"{walk_id}_{stop['stop_no']}\",\n",
        "                \"walk_name\": name, \"walk_id\": walk_id, \"cuisine_type\": cuisine_req,\n",
        "                \"is_veg_friendly\": dietary_req, \"rest_address\": full_addr, \"city\": city, **stop\n",
        "            })\n",
        "\n",
        "        sh.worksheet(OUTPUT_TAB_NAME).append_rows(final_rows)\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error processing {name}: {e}\")\n",
        "        return False\n",
        "\n",
        "def run_batch_process():\n",
        "    sh = gc.open(WORKBOOK_NAME)\n",
        "    input_sheet = sh.worksheet(INPUT_TAB_NAME)\n",
        "\n",
        "    # Check if Status column exists, if not, add it\n",
        "    headers = input_sheet.row_values(1)\n",
        "    if \"Status\" not in headers:\n",
        "        input_sheet.update_cell(1, len(headers) + 1, \"Status\")\n",
        "        input_sheet.update_cell(1, len(headers) + 2, \"Processed_At\")\n",
        "        headers = input_sheet.row_values(1)\n",
        "\n",
        "    status_col_idx = headers.index(\"Status\") + 1\n",
        "    time_col_idx = headers.index(\"Processed_At\") + 1\n",
        "\n",
        "    # Get data\n",
        "    records = input_sheet.get_all_records()\n",
        "    print(f\"üöÄ Found {len(records)} entries in queue.\")\n",
        "\n",
        "    for i, row in enumerate(records):\n",
        "        # Skip if already completed\n",
        "        if row.get(\"Status\") == \"Completed\":\n",
        "            continue\n",
        "\n",
        "        if not row['WALK_NAME'] or not row['WALK_LOCATION']:\n",
        "            continue\n",
        "\n",
        "        success = process_single_walk(sh, row)\n",
        "\n",
        "        if success:\n",
        "            # Update the specific row in the input sheet (i+2 because GSheets is 1-indexed and has header)\n",
        "            input_sheet.update_cell(i + 2, status_col_idx, \"Completed\")\n",
        "            input_sheet.update_cell(i + 2, time_col_idx, time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
        "            print(f\"‚úÖ Successfully curated: {row['WALK_NAME']}\")\n",
        "        else:\n",
        "            input_sheet.update_cell(i + 2, status_col_idx, \"Failed/No Data\")\n",
        "\n",
        "        time.sleep(2) # Prevent API rate limiting\n",
        "\n",
        "run_batch_process()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "YVnG3G9jJteS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}